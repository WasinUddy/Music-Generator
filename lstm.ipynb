{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "music21: Certain music21 functions might need these optional packages: matplotlib, scipy;\n",
      "                   if you run into errors, install them by following the instructions at\n",
      "                   http://mit.edu/music21/doc/installing/installAdditional.html\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install music21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:20<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "notes = []\n",
    "\n",
    "for file in tqdm(glob.glob(\"midi/*.mid\")):\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "\n",
    "    try: # file has instrument parts\n",
    "        s2 = instrument.partitionByInstrument(midi)\n",
    "        notes_to_parse = s2.parts[0].recurse() \n",
    "    except: # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Notes\n",
    "with open('notes.pkl', 'wb') as f:\n",
    "    pickle.dump(notes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Notes\n",
    "with open('notes.pkl', 'rb') as f:\n",
    "    notes = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab = len(set(notes))\n",
    "n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "\n",
    "\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "\n",
    "for i in range(0, len(notes) - sequence_length, 1):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "# normalize input\n",
    "network_input = network_input / float(n_vocab)\n",
    "\n",
    "network_output = to_categorical(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104939, 100, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104939, 270)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Model\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(256, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))              \n",
    "model.add(CuDNNLSTM(128, return_sequences=True))\n",
    "model.add(CuDNNLSTM(64))\n",
    "\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104939 samples\n",
      "Epoch 401/1000\n",
      "104939/104939 [==============================] - 23s 216us/sample - loss: 0.5810\n",
      "Epoch 402/1000\n",
      "104939/104939 [==============================] - 24s 233us/sample - loss: 0.5793\n",
      "Epoch 403/1000\n",
      "104939/104939 [==============================] - 25s 239us/sample - loss: 0.5755 - - ETA: 0s - lo\n",
      "Epoch 404/1000\n",
      "104939/104939 [==============================] - 23s 221us/sample - loss: 0.5756\n",
      "Epoch 405/1000\n",
      "104939/104939 [==============================] - 24s 225us/sample - loss: 0.5755\n",
      "Epoch 406/1000\n",
      "104939/104939 [==============================] - 24s 227us/sample - loss: 0.5739- ETA: \n",
      "Epoch 407/1000\n",
      "104939/104939 [==============================] - 23s 221us/sample - loss: 0.5701 - loss: 0\n",
      "Epoch 408/1000\n",
      "104939/104939 [==============================] - 23s 224us/sample - loss: 0.5749 - loss: 0 - ETA: 6s - ETA:\n",
      "Epoch 409/1000\n",
      "104939/104939 [==============================] - 23s 223us/sample - loss: 0.5714 - loss: 0.571 - ETA: 0s - loss: 0.5\n",
      "Epoch 410/1000\n",
      "104939/104939 [==============================] - 24s 226us/sample - loss: 0.5718 - loss: 0.571\n",
      "Epoch 411/1000\n",
      "104939/104939 [==============================] - 24s 224us/sample - loss: 0.5659\n",
      "Epoch 412/1000\n",
      "104939/104939 [==============================] - 23s 223us/sample - loss: 0.5679\n",
      "Epoch 413/1000\n",
      "104939/104939 [==============================] - 24s 224us/sample - loss: 0.5654 - lo - ETA - ETA: 0s - \n",
      "Epoch 414/1000\n",
      "104939/104939 [==============================] - 23s 222us/sample - loss: 0.5704\n",
      "Epoch 415/1000\n",
      "104939/104939 [==============================] - 25s 235us/sample - loss: 0.5658\n",
      "Epoch 416/1000\n",
      "104939/104939 [==============================] - 24s 232us/sample - loss: 0.5667\n",
      "Epoch 417/1000\n",
      "104939/104939 [==============================] - 24s 227us/sample - loss: 0.5607\n",
      "Epoch 418/1000\n",
      "104939/104939 [==============================] - 23s 223us/sample - loss: 0.5609\n",
      "Epoch 419/1000\n",
      "104939/104939 [==============================] - 25s 236us/sample - loss: 0.5594\n",
      "Epoch 420/1000\n",
      "104939/104939 [==============================] - 24s 232us/sample - loss: 0.5581\n",
      "Epoch 421/1000\n",
      "104939/104939 [==============================] - 23s 221us/sample - loss: 0.5576\n",
      "Epoch 422/1000\n",
      "104939/104939 [==============================] - 24s 227us/sample - loss: 0.5565\n",
      "Epoch 423/1000\n",
      "104939/104939 [==============================] - 24s 227us/sample - loss: 0.5576\n",
      "Epoch 424/1000\n",
      "104939/104939 [==============================] - 23s 223us/sample - loss: 0.5531 - loss: 0\n",
      "Epoch 425/1000\n",
      "104939/104939 [==============================] - 25s 236us/sample - loss: 0.5523\n",
      "Epoch 426/1000\n",
      " 81408/104939 [======================>.......] - ETA: 5s - loss: 0.5394"
     ]
    }
   ],
   "source": [
    "#model.load_weights(\"weight/weights-improvement-400-0.5798-bigger.hdf5\")\n",
    "filepath = \"weight/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(network_input, network_output, epochs=1000, batch_size=128, callbacks=callbacks_list, initial_epoch=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
